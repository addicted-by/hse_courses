{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Natural Language Processing\n",
    "\n",
    "## <font color=\"green\"> Home assignment 1 </font>: N-gram Language Model\n",
    "\n",
    "### Work had been done by: Ryabykin Aleksey\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(nltk.bigrams(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate(cfd, first_word, length = 50):\n",
    "    word = first_word\n",
    "    print(word, end = ' ')\n",
    "    for i in range(length):\n",
    "        pairs = cfd[word].most_common()\n",
    "        next_words = [word for word, freq in pairs]\n",
    "        freqs = [freq for word, freq in pairs]\n",
    "        word = random.choices(next_words, weights = freqs)[0]\n",
    "        print(word, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me , and it to a gentleman , \" I am sure Marianne ; and words in the next morning was summoned to have been taken the drawing - trees in many pursuits and all advise you to Mrs . Sir John Dashwood alone could even SHE would give offence would "
     ]
    }
   ],
   "source": [
    "generate(cfd, \"Me\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concatenate all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "texts_list = [text1, text2, text3, text4, text5, text6, text7, text8, text9]\n",
    "for text in texts_list:\n",
    "    tokens += text.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from collections import deque \n",
    "\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, tokens: List[str], n_grams:int=2) -> None:\n",
    "        '''\n",
    "\n",
    "        Initializing text generator. Collecting all `2..n`-grams.\n",
    "        The idea is that in case if we can't find such `n`-gram, it will apply the \n",
    "        `n-1`-gramm method and so on.  \n",
    "\n",
    "        ## Inputs:\n",
    "        \n",
    "        * `tokens` - list of tokens from all texts. Just for this case. It can be generalized, I think.\n",
    "        * `n_grams` - the number of grams that will be separated and used in the algorithm.\n",
    "        '''\n",
    "\n",
    "        assert n_grams > 1 and n_grams < 100, \"Wrong `n_grams` value\"\n",
    "\n",
    "        print(f\"Collecting {n_grams}-grams freq...\")\n",
    "        first = True\n",
    "        ngrams_as_bigrams = []\n",
    "\n",
    "        for n in tqdm(range(2, n_grams + 1)):\n",
    "            ngrams = nltk.ngrams(tokens, n)\n",
    "            ngrams_as_bigrams.extend([((t[:-1]), t[-1]) for t in ngrams])\n",
    "        self.cfd = nltk.ConditionalFreqDist(ngrams_as_bigrams)\n",
    "        self.n_grams = n_grams\n",
    "\n",
    "    def generate_word(self, input_sentence: Tuple[str]) -> str:\n",
    "        '''\n",
    "        Function that generates the following word by the given sequence of n-grams.\n",
    "        The main approach the same as it was on the lecture: \n",
    "        it's just a weighted by frequencies random choice from all possible following \n",
    "        words from the initial texts. \n",
    "        \n",
    "        ## Inputs:\n",
    "        \n",
    "        * `input_sentence` - sequence of `n_grams`.\n",
    "\n",
    "        ## Returns:\n",
    "        \n",
    "        * `word` - the following word.\n",
    "        '''\n",
    "\n",
    "        sentence = input_sentence\n",
    "        pairs = self.cfd[sentence].most_common()\n",
    "        next_words = [word for word, freq in pairs]\n",
    "        freqs = [freq for word, freq in pairs]\n",
    "        word = random.choices(next_words, weights=freqs)[0]\n",
    "        return word\n",
    "    \n",
    "    def generate(self, first_word: str=\"I\", length=100) -> str:\n",
    "        '''\n",
    "        The function for generating text by the first word. It can be generalized to the given sequence as well.\n",
    "        But in case of one first word there is simple approach: firstly is to find the following word by 2-gram\n",
    "        generation, add it to the sequence with length `n-grams - 1` and so on from 2 to n-gram.\n",
    "        Here is deque with fixed length in usage that helps us to save the context for prediction the following word.\n",
    "        It simplifies the work with sliding through `n-gramms`.\n",
    "\n",
    "        ## Inputs:\n",
    "\n",
    "        * `first_word` - string with first word;\n",
    "        * `length` - length of the sentence to generate.\n",
    "        \n",
    "        ## Returns: \n",
    "\n",
    "        * `generated` - generated sentence.\n",
    "        '''\n",
    "        queue = deque([first_word], maxlen=self.n_grams - 1)\n",
    "        generated = [first_word]\n",
    "        print(first_word, end=' ')\n",
    "        \n",
    "        assert self.cfd[tuple(queue)], \"Cannot find this word in the dictionary\" \n",
    "        \n",
    "        new_word = self.generate_word(tuple(queue))\n",
    "        print(new_word, end=' ')\n",
    "        queue.append(new_word)\n",
    "        for i in range(length):\n",
    "            not_generated = True\n",
    "            while not_generated:\n",
    "                assert len(queue) > 0, \"Something went wrong\"\n",
    "\n",
    "\n",
    "                if tuple(queue) in self.cfd.keys():\n",
    "                    new_word = self.generate_word(tuple(queue))\n",
    "                    queue.append(new_word)\n",
    "                    not_generated = False\n",
    "                else:\n",
    "                    queue.popleft()\n",
    "                    new_word = self.generate_word(tuple(queue))\n",
    "                    queue.append(new_word)\n",
    "                    not_generated = False\n",
    "            print(new_word, end=' ')\n",
    "            generated.append(new_word)\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting 5-grams freq...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.34it/s]\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(tokens, n_grams=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I say ; your whales must be seen before they can be killed ; and this sunken - eyed young Platonist will tow you ten wakes round the world , at another she would seclude herself from it for ever , and has made all those over whom she had any influence , cast him off likewise . Surely , after doing so , she cannot be imagined liable to any impression of sorrow or of joy on his account -- she cannot be interested in any thing that befalls him .-- She would not be frightened from paying him those attentions "
     ]
    }
   ],
   "source": [
    "generated_text = generator.generate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether it is working or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'whales': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.cfd[('I', 'say', ';', 'your')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.cfd[('I', 'remained', 'in', 'this', 'whales')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it is. Let's compare with the initial algo. Let's make the same cfd for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:33<00:00, 11.15s/it]\n"
     ]
    }
   ],
   "source": [
    "ngrams_as_bigrams = []\n",
    "cfd = nltk.ConditionalFreqDist(nltk.bigrams(tokens))\n",
    "for n in tqdm(range(3, 5 + 1)):\n",
    "        ngrams = nltk.ngrams(tokens, n)\n",
    "        ngrams_as_bigrams.extend([((t[:-1]), t[-1]) for t in ngrams])\n",
    "        cfd += nltk.ConditionalFreqDist(ngrams_as_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I that of hope of them , influence your behaviour of a paper . \" I don ' s sleek , a trifling importance , says 0 it might plug it ; for the open is called . What are committed . \" You Gotta Have a moment . The Constitution of appointment is technically fast asleep ; yet now 18 / New Hampshire , Quohog , bravely he ' t repeat it ! That is the Britons . But he U6 ... weighs ... CONCORDE : Burn ! FRENCH GUARD # 2 days of blubber into the principle , flows "
     ]
    }
   ],
   "source": [
    "generate(cfd, 'I', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'I': 3, 'you': 3})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd[('I', 'that')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'air': 24, 'sea': 18, 'ocean': 9, 'independence': 3, 'atmosphere': 3, 'field': 3, 'jaw': 3, 'firmament': 3, 'door': 3, 'market': 3, ...})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd[('the', 'open')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd[('the', 'open', 'is')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it is not working in the same way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7abe41bf88626c8179a12d706309ac1665b0164ec3bd4c11d7418ed9f0904ed3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
